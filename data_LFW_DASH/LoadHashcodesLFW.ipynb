{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.io as sio\n",
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_prefix = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the Data from a Predefined Matrix [Scraped a while ago by Svebor]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labels is a list showing which person corresponds to which image [Note: there are some people that show up multiple times]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    1    2 ..., 5746 5747 5748]\n"
     ]
    }
   ],
   "source": [
    "# how to load ground truth labels\n",
    "gt_name = 'LFW_all_subjects_id.mat'\n",
    "gt_file_full = data_prefix + gt_name\n",
    "gt_mat = sio.loadmat(gt_file_full)\n",
    "labels = np.squeeze(gt_mat['all_subjects_ids'])\n",
    "print labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 5748 People in this LFW dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading 512 bit long hashcodes that were generated from the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# how to load hashcodes\n",
    "hashcodes_name = 'LFW_hash512_randomcrop_prelu_newproto_rgb_notV7.3.mat'\n",
    "hashcodes_file_full = data_prefix + hashcodes_name\n",
    "hashcodes_mat = sio.loadmat(hashcodes_file_full)\n",
    "#print hashcodes_mat['templates']\n",
    "all_templates = hashcodes_mat['templates']\n",
    "# all templates contains: subject_name, subject_id, file, features (actually hashcodes in this case)\n",
    "nb_samples = hashcodes_mat['templates'].shape[1]\n",
    "all_samples_tmp = []\n",
    "all_samples_files = []\n",
    "for i in range(nb_samples):\n",
    "    all_samples_tmp.append(np.squeeze(all_templates[0,i][3]))\n",
    "    all_samples_files.append(str(np.squeeze(all_templates[0,i][2])))\n",
    "all_samples = np.asarray(all_samples_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AJ_Cook_0001.jpg', 'AJ_Lamas_0001.jpg', 'Aaron_Eckhart_0001.jpg', 'Aaron_Guiel_0001.jpg', 'Aaron_Patterson_0001.jpg', 'Aaron_Peirsol_0001.jpg', 'Aaron_Peirsol_0002.jpg', 'Aaron_Peirsol_0003.jpg', 'Aaron_Peirsol_0004.jpg', 'Aaron_Pena_0001.jpg']\n"
     ]
    }
   ],
   "source": [
    "print all_samples_files[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  9.99719501e-01   9.99999583e-01   9.92673457e-01 ...,   1.00000000e+00\n",
      "    1.00000000e+00   1.06802311e-07]\n",
      " [  6.81201158e-08   3.98614723e-03   1.00000000e+00 ...,   9.99999821e-01\n",
      "    2.63930566e-12   7.86280156e-12]]\n",
      "[[ True  True  True ...,  True  True False]\n",
      " [False False  True ...,  True False False]]\n",
      "(13233, 512)\n"
     ]
    }
   ],
   "source": [
    "print all_samples[:2,:]\n",
    "# hash codes should actually be binarized.\n",
    "# Check what is the best way to represent binary codes in python\n",
    "print (all_samples>0.5)[:2,:]\n",
    "print all_samples.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting distances between each hashcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# how to load precomputed distance matrix\n",
    "fulldist_name = 'LFW_full_hamming_dist.mat'\n",
    "fulldist_file = data_prefix + fulldist_name\n",
    "fulldist = sio.loadmat(fulldist_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fulldist_np = fulldist['full_hamming_dist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13233, 13233)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fulldist_np.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Scraping LFW dataset from CAVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13143\n",
      "13143\n"
     ]
    }
   ],
   "source": [
    "f = open('lfw_attributes.txt', 'r')\n",
    "\n",
    "f.readline() # Header\n",
    "f.readline() # Attributes List\n",
    "\n",
    "labels = []\n",
    "data = []\n",
    "count = 0\n",
    "for line in f:\n",
    "    count += 1\n",
    "    line = line.split(\"\\n\")[0]\n",
    "    arr = line.split(\"\t\")\n",
    "    label = arr[0] \n",
    "    features = []\n",
    "    for elem in arr[2:]:\n",
    "        if float(elem) <= 0:\n",
    "            features.append(0)\n",
    "        else:\n",
    "            features.append(1)\n",
    "    retVal = []\n",
    "    for elem in label.split():\n",
    "        retVal.append(elem)\n",
    "    labels.append(\"_\".join(retVal) + \"_\" + str(arr[1]).zfill(4) + \".jpg\")\n",
    "    data.append(np.array(features))\n",
    "print len(labels)\n",
    "print str(count)\n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13143\n",
      "13233\n",
      "---\n",
      "13143\n",
      "13233\n"
     ]
    }
   ],
   "source": [
    "# print all_samples_files[2]\n",
    "# print labels[0]\n",
    "# print labels[0] in all_samples_files[2]\n",
    "\n",
    "print len(labels)\n",
    "print len(all_samples_files)\n",
    "labels_count = 0\n",
    "hash_count = 0\n",
    "count = 0\n",
    "\n",
    "dictionary = {}\n",
    "for elem in labels:\n",
    "    dictionary[elem] = True\n",
    "count = 0\n",
    "colDel = []\n",
    "for elem in all_samples_files:\n",
    "    if elem not in dictionary:\n",
    "        colDel.append(count)\n",
    "    count += 1\n",
    "\n",
    "print '---'\n",
    "print len(labels)\n",
    "print len(all_samples_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n"
     ]
    }
   ],
   "source": [
    "print len(colDel)\n",
    "\n",
    "count = len(colDel) - 1\n",
    "while count >= 0:\n",
    "    fulldist_np = scipy.delete(fulldist_np, colDel[count], 0)  # delete second row of A\n",
    "    fulldist_np = scipy.delete(fulldist_np, colDel[count], 1)  # delete second column of C\n",
    "    count = count - 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13143\n",
      "13143\n",
      "(13143, 13143)\n"
     ]
    }
   ],
   "source": [
    "print len(labels)\n",
    "print len(fulldist_np[0])\n",
    "print fulldist_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73\n"
     ]
    }
   ],
   "source": [
    "print len(data[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "data_dist = distance.cdist(data, data, 'hamming')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12328767123287671"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data_dist)\n",
    "data_dist[0][100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "normalized_hash_dist= fulldist_np/512.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.431640625\n",
      "221\n"
     ]
    }
   ],
   "source": [
    "print normalized_hash_dist[2000][1300]\n",
    "print fulldist_np[2000][1300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.232876712329\n"
     ]
    }
   ],
   "source": [
    "print data_dist[6][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n",
      "(13143, 13143)\n",
      "<type 'numpy.ndarray'>\n",
      "(13143, 13143)\n"
     ]
    }
   ],
   "source": [
    "print type(data_dist)\n",
    "print data_dist.shape\n",
    "print type(normalized_hash_dist)\n",
    "print normalized_hash_dist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-10 -10 -10]\n",
      " [-10 -10 -10]]\n"
     ]
    }
   ],
   "source": [
    "x1 = np.array([1,2,3])\n",
    "x2 = np.array([4,5,6])\n",
    "x3 = []\n",
    "x3.append(x1)\n",
    "x3.append(x2)\n",
    "x3 = np.array(x3)\n",
    "\n",
    "\n",
    "x11 = np.array([11,12,13])\n",
    "x12 = np.array([14,15,16])\n",
    "x13 = []\n",
    "x13.append(x11)\n",
    "x13.append(x12)\n",
    "x13 = np.array(x13)\n",
    "\n",
    "print np.subtract(x3, x13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.subtract(normalized_hash_dist, fulldist_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "from scipy.spatial import distance\n",
    "hash_dist = distance.cdist(all_samples, all_samples, 'euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13233\n"
     ]
    }
   ],
   "source": [
    "print len(hash_dist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13233\n"
     ]
    }
   ],
   "source": [
    "print len(hash_dist[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  5  5  5  6  7  7  8  9 10 11 12 13 13 14 14 14 14 15 16\n",
      " 17 18 18 18 18 19 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20]\n"
     ]
    }
   ],
   "source": [
    "print labels[0:50]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.1039511579\n",
      "9.2625290269\n",
      "10.0453316283\n",
      "11.301439035\n",
      "8.92844945144\n",
      "10.0961797268\n"
     ]
    }
   ],
   "source": [
    "print hash_dist[37][36]\n",
    "print hash_dist[37][38]\n",
    "print hash_dist[36][38]\n",
    "print hash_dist[35][39]\n",
    "print hash_dist[39][40]\n",
    "print hash_dist[40][35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best = 0\n",
    "for elem in hash_dist:\n",
    "    best = max(best, max(elem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best2 = 0\n",
    "for elem in fulldist_np:\n",
    "    best2 = max(best2, max(elem))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "387"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dist_np = fulldist_np / (best2 / 100.0)\n",
    "has_np = hash_dist / (best / 100.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92.7648578811\n",
      "359\n"
     ]
    }
   ],
   "source": [
    "print max(dist_np[100])\n",
    "print max(fulldist_np[100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
